{
 "cells": [
  {
   "cell_type": "raw",
   "id": "382683c4",
   "metadata": {},
   "source": [
    "Strategy:\n",
    "    After we extract all the company names and its websites from google \n",
    "    For each file in the results names folder => We extract the emails one after the other \n",
    "    We save each file again updating the emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e988ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb78f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1db606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "39c1761e",
   "metadata": {},
   "source": [
    "## logic:\n",
    "1. For each entry or row\n",
    "2. If website is given => Extract contact page and try to extract emails\n",
    "3. If website is not given => Extract website => Extract contact page and try to extract emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ea94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiating the browser\n",
    "options = webdriver.ChromeOptions()\n",
    "path = \"../chrome\\chromedriver.exe\"\n",
    "service = Service(executable_path=path)\n",
    "browser = webdriver.Chrome(service=service,options=options)\n",
    "browser.maximize_window()\n",
    "\n",
    "browser.set_page_load_timeout(60) # only for 5 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32475ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmailFromWebsite(url):\n",
    "    global browser \n",
    "    \n",
    "    emails = set()\n",
    "    # opening with selnium\n",
    "    browser.get(url)\n",
    "    \n",
    "    # from any element which has @ in their text\n",
    "    elems = browser.find_elements(\"xpath\",\"//*[contains(text(), '@')]\")\n",
    "    for elem in elems:\n",
    "        es = ((re.findall(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", elem.text, re.I)))\n",
    "        emails.update(es)\n",
    "    \n",
    "    if len(emails) == 0:\n",
    "        try:\n",
    "            \n",
    "            time.sleep(1)\n",
    "            button = browser.find_element(By.XPATH, \"//a[contains(text(),'contact')]\") \n",
    "            browser.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "            elems = browser.find_elements(\"xpath\",\"//*[contains(text(), '@')]\")\n",
    "            for elem in elems:\n",
    "                es = ((re.findall(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", elem.text, re.I)))\n",
    "                emails.update(es)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return \";\".join(emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f4e196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'info@safapharm.com'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://safapharm.com\"\n",
    "getEmailFromWebsite(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c10ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWebsiteFromName(name):\n",
    "    global browser\n",
    "    global country\n",
    "    url_base = \"https://www.google.com/search?q=\"\n",
    "    url = url_base + name + \" \" + country\n",
    "\n",
    "    # opening a url:\n",
    "    browser.get(url)\n",
    "    elems = browser.find_elements(\"xpath\",\"//a[@jsname='UWckNb']\")\n",
    "\n",
    "    # check first\n",
    "    elem = elems[0]\n",
    "    link = elem.text.split(\"\\n\")[2]\n",
    "    \n",
    "    marketplaces = [\n",
    "        'justdail',\n",
    "        'amazon',\n",
    "        'cphi',\n",
    "        'dnb',\n",
    "        'wikipedia',\n",
    "        'linkedin',\n",
    "        'indiamart'\n",
    "    ]\n",
    "    \n",
    "    for m in marketplaces:\n",
    "        if m in link:\n",
    "            return None\n",
    "    \n",
    "    if 'http' in link:\n",
    "        if \"›\" in link:\n",
    "            link = link.split(\"›\")[0].strip()\n",
    "\n",
    "        for m in marketplaces:\n",
    "            if m in link:\n",
    "                return None\n",
    "            \n",
    "        return link\n",
    "    else:\n",
    "        # check second\n",
    "        elem = elems[1]\n",
    "        link = elem.text.split(\"\\n\")[2]\n",
    "        if 'http' in link:\n",
    "            if \"›\" in link:\n",
    "                link = link.split(\"›\")[0].strip()\n",
    "            return link\n",
    "        else:\n",
    "            # check third\n",
    "            elem = elems[1]\n",
    "            link = elem.text.split(\"\\n\")[2]\n",
    "            if 'http' in link:\n",
    "                if \"›\" in link:\n",
    "                    link = link.split(\"›\")[0].strip()\n",
    "                return link\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe207628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.julphar.net'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Julphar Iraq\"\n",
    "links = extractWebsiteFromName(name)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da6666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEmail(row):\n",
    "    \n",
    "    name = row['name']\n",
    "    website = row['website']\n",
    "    \n",
    "    emails_all = []\n",
    "    \n",
    "    if type(website) != float:\n",
    "        # extract emails from website:\n",
    "        emails = getEmailFromWebsite(website)\n",
    "        emails_all.extend(emails.split(\";\"))\n",
    "        \n",
    "    else:\n",
    "        # try extracting website from company name\n",
    "        website = extractWebsiteFromName(name)\n",
    "        row['website']=website\n",
    "        \n",
    "        emails = getEmailFromWebsite(website)\n",
    "        emails_all.extend(emails.split(\";\"))\n",
    "    \n",
    "    row['emails']=\";\".join(emails_all)\n",
    "    return row\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb39680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = \"Egypt\"\n",
    "files = os.listdir(\"../results/names/{}\".format(country))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6998603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../results/emails/{}\".format(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab61a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zawiyat Razin_companies.csv', '`Izbat al Burj_companies.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e45eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :: 0\n",
      "Started for file :: Abjij_companies.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [03:34<00:00, 11.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :: 1\n",
      "Started for file :: Abnub_companies.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [02:23<00:00, 17.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :: 2\n",
      "Started for file :: Abu al Matamir_companies.csv\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m failed_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m existing_rows_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/names/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(country,file))\n\u001b[0;32m     10\u001b[0m rows \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(rows):\n",
      "File \u001b[1;32mD:\\usefull\\softwares\\ana\\anacondalib\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\usefull\\softwares\\ana\\anacondalib\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\usefull\\softwares\\ana\\anacondalib\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\usefull\\softwares\\ana\\anacondalib\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\usefull\\softwares\\ana\\anacondalib\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mD:\\usefull\\softwares\\ana\\anacondalib\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:557\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "\n",
    "for ind, file in enumerate(files):\n",
    "    print(\"Index ::\",ind)\n",
    "    print(\"Started for file ::\",file)\n",
    "    \n",
    "    updated_rows = []\n",
    "    failed_rows = []\n",
    "    existing_rows_names = []\n",
    "\n",
    "    df = pd.read_csv(\"../results/names/{}/{}\".format(country,file))\n",
    "    rows = df.to_dict('records')\n",
    "    \n",
    "    for row in tqdm.tqdm(rows):\n",
    "        if row['name'] not in existing_rows_names:\n",
    "            try:\n",
    "                n = extractEmail(row)\n",
    "                updated_rows.append(n)\n",
    "            except:\n",
    "                failed_rows.append(row)\n",
    "                row['emails']=\"\"\n",
    "                updated_rows.append(row)\n",
    "                pass\n",
    "            \n",
    "        existing_rows_names.append(row['name'])\n",
    "    \n",
    "    # saving\n",
    "    df = pd.DataFrame(updated_rows)\n",
    "    df.to_csv(\"../results/emails/{}/{}\".format(country,file),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f31bd7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162486ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :: 0\n",
      "Started for file :: companies_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [12:20<00:00, 10.15s/it]\n"
     ]
    }
   ],
   "source": [
    "## When it is taking too much time for a certain website:\n",
    "\n",
    "for ind, file in enumerate(files):\n",
    "    print(\"Index ::\",ind)\n",
    "    print(\"Started for file ::\",file)\n",
    "    \n",
    "    updated_rows = []\n",
    "    failed_rows = []\n",
    "    existing_rows_names = []\n",
    "\n",
    "    df = pd.read_csv(\"../results/names/{}/{}\".format(country,file))\n",
    "    rows = df.to_dict('records')\n",
    "    \n",
    "    for row in tqdm.tqdm(rows[46:]):\n",
    "        if row['name'] not in existing_rows_names:\n",
    "            try:\n",
    "                n = extractEmail(row)\n",
    "                updated_rows.append(n)\n",
    "            except:\n",
    "                failed_rows.append(row)\n",
    "                row['emails']=\"\"\n",
    "                updated_rows.append(row)\n",
    "                pass\n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dacdfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Austex Pharmaceutical PTE LTD',\n",
       " 'phone': '062008 92433',\n",
       " 'website': 'http://www.austexpharma.com/',\n",
       " 'address': '81 UBI Avenue 4 #06-03 UB.ONE',\n",
       " 'emails': 'contact@austexpharma.com'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to update the index accordingly\n",
    "updated_rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e46f5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "df = pd.DataFrame(updated_rows)\n",
    "df.to_csv(\"../results/emails/{}/{}\".format(country,file),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1a59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
